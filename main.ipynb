{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.messages import  HumanMessage\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "import os\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.chains import create_extraction_chain\n",
    "from langchain_community.agent_toolkits import create_sql_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"./data.txt\")\n",
    "docs = loader.load()\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "# splits = text_splitter.split_documents(docs) #if we need to split doc.\n",
    "vectorstore = Chroma.from_documents(documents=docs, embedding=OpenAIEmbeddings())\n",
    "\n",
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"name\": {\"type\": \"string\"},\n",
    "        \"phone_number\": {\"type\": \"integer\"},\n",
    "    },\n",
    "    \"required\": [],\n",
    "}\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = \"\"\"Imagine you are a receptionist at South Bay Dental Office. \"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "contextualize_q_chain = contextualize_q_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB_URI = \"sqlite:///./Chinook.db\"\n",
    "# print(DB_URI)\n",
    "# db = SQLDatabase.from_uri(DB_URI)\n",
    "\n",
    "# create_data_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "# create_agent_executor = create_sql_agent(create_data_llm, db=db, agent_type=\"openai-tools\", verbose=False)\n",
    "# create_agent_executor.invoke(\n",
    "#     f\"\"\"Create Table name appointment table if already not exist. where colums are Phone Number : Integer, Name : String, Date : Date , Time:time fields.\"\"\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_system_prompt = \"\"\"Imagine you are a receptionist at South Bay Dental Office. \\\n",
    "    {context}\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def contextualized_question(input: dict):\n",
    "    if input.get(\"chat_history\"):\n",
    "        return contextualize_q_chain\n",
    "    else:\n",
    "        return input[\"question\"]\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        context=contextualized_question | retriever\n",
    "    )\n",
    "    | qa_prompt\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Himlay:  riya 9624788668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/himalaypatel/Documents/HimalayWork/Learning/LangChain-AI-Voice-Call-asistant/venv/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Phone and name into database\n",
      "sqlite:///Chinook.db\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_list_tables` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mappointment\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_schema` with `{'table_names': 'appointment'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE appointment (\n",
      "\tid INTEGER, \n",
      "\tname TEXT DEFAULT '', \n",
      "\tphone_number INTEGER DEFAULT '', \n",
      "\tPRIMARY KEY (id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from appointment table:\n",
      "id\tname\tphone_number\n",
      "1\tHimalay\t9624788668\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3mThe appointment table has the following schema:\n",
      "\n",
      "- id: INTEGER\n",
      "- name: TEXT\n",
      "- phone_number: INTEGER\n",
      "\n",
      "To insert the data into the appointment table, I will use the following query:\n",
      "\n",
      "```sql\n",
      "INSERT INTO appointment (phone_number, name)\n",
      "VALUES (9624788668, 'riya')\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "user converted answer - [{'name': 'riya', 'phone_number': 9624788668}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "\n",
    "llmdata = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "def check_phone_name(converted_answer):\n",
    "  if converted_answer.get('phone_number') and converted_answer.get('phone_number') != 1234567890:\n",
    "    print(\"Adding Phone and name into database\")\n",
    "    # DB_URI = f\"mysql://{os.environ['DB_USER']}:{os.environ['DB_PASSWORD']}@{os.environ['DB_HOST']}:{os.environ['DB_PORT']}/{os.environ['DB_NAME']}\"\n",
    "    DB_URI = \"sqlite:///Chinook.db\"\n",
    "    print(DB_URI)\n",
    "    db = SQLDatabase.from_uri(DB_URI)\n",
    "  \n",
    "    insert_data_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "    agent_executor = create_sql_agent(insert_data_llm, db=db, agent_type=\"openai-tools\", verbose=True)\n",
    "    agent_executor.invoke(\n",
    "      # f\"Add phone_number : {converted_answer.get('phone_number')} and name : {converted_answer.get('name')} insert data into appointment table make date and time as current date and time.\"\n",
    "      f\"\"\"Insert the following data into the appointment table:\n",
    "\n",
    "      - Phone Number: {converted_answer.get('phone_number')}\n",
    "      - Name: {converted_answer.get('name')}\n",
    "\n",
    "      \"\"\"\n",
    "    )\n",
    "    \n",
    "for i in range(5):\n",
    "  \n",
    "  question = input(\"Himalay: \")\n",
    "  print(\"Himlay: \", question)\n",
    "  \n",
    "  \n",
    "  chain = create_extraction_chain(schema, llmdata)\n",
    "  converted_answer = chain.run(question)\n",
    "  if len(converted_answer) > 0:\n",
    "    check_phone_name(converted_answer[0])\n",
    "  print(f\"user converted answer - {converted_answer}\")\n",
    "  \n",
    "  ai_msg = rag_chain.invoke({\"question\": question, \"chat_history\": chat_history})\n",
    "  \n",
    "  \n",
    "  print(\"AI Response: \",ai_msg)\n",
    "  print(\"--------------------------------------------------------------\")\n",
    "  chat_history.extend([HumanMessage(content=question), ai_msg])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
