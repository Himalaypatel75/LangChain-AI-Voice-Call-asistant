{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.messages import  HumanMessage\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "import os\n",
    "from langchain.sql_database import SQLDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"./data.txt\")\n",
    "docs = loader.load()\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "# splits = text_splitter.split_documents(docs) #if we need to split doc.\n",
    "vectorstore = Chroma.from_documents(documents=docs, embedding=OpenAIEmbeddings())\n",
    "\n",
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"name\": {\"type\": \"string\"},\n",
    "        \"phone_number\": {\"type\": \"integer\"},\n",
    "    },\n",
    "    \"required\": [],\n",
    "}\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = \"\"\"Imagine you are a receptionist at South Bay Dental Office. \"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "contextualize_q_chain = contextualize_q_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_system_prompt = \"\"\"Imagine you are a receptionist at South Bay Dental Office. \\\n",
    "    {context}\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def contextualized_question(input: dict):\n",
    "    if input.get(\"chat_history\"):\n",
    "        return contextualize_q_chain\n",
    "    else:\n",
    "        return input[\"question\"]\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        context=contextualized_question | retriever\n",
    "    )\n",
    "    | qa_prompt\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Himlay:  riya 958478954\n",
      "Adding Phone and name into database\n",
      "sqlite:///./Chinook.db\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_list_tables` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mappointment\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_schema` with `{'table_names': 'appointment'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE appointment (\n",
      "\tname TEXT, \n",
      "\tdate TEXT, \n",
      "\tphone_number TEXT, \n",
      "\ttime TEXT\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from appointment table:\n",
      "name\tdate\tphone_number\ttime\n",
      "\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_query` with `{'query': \"INSERT INTO appointment (name, date, phone_number, time) VALUES ('riya', date('now'), '958478954', time('now'))\"}`\n",
      "responded: The appointment table exists and has the following columns: name, date, phone_number, and time. \n",
      "\n",
      "Now I can insert the data into the appointment table with the given values.\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mThe data has been successfully inserted into the appointment table.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "user converted answer - [{'name': 'riya', 'phone_number': 958478954}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response:  content='Hi, this is South Bay Dental Office, how may I help you? Are you a new or existing patient?'\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "from langchain.chains import create_extraction_chain\n",
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "llmdata = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "def check_phone_name(converted_answer):\n",
    "  if converted_answer.get('phone_number') and converted_answer.get('phone_number') != 1234567890:\n",
    "    print(\"Adding Phone and name into database\")\n",
    "    # DB_URI = f\"mysql://{os.environ['DB_USER']}:{os.environ['DB_PASSWORD']}@{os.environ['DB_HOST']}:{os.environ['DB_PORT']}/{os.environ['DB_NAME']}\"\n",
    "    DB_URI = \"sqlite:///./Chinook.db\"\n",
    "    print(DB_URI)\n",
    "    db = SQLDatabase.from_uri(DB_URI)\n",
    "  \n",
    "    create_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "    agent_executor = create_sql_agent(create_llm, db=db, agent_type=\"openai-tools\", verbose=True)\n",
    "    agent_executor.invoke(\n",
    "      f\"Add phone_number : {converted_answer.get('phone_number')} and name : {converted_answer.get('name')} data into appointment table make date and time as current date and time, if table not exist then create with colum name, date, phone_number, time. \"\n",
    "    )\n",
    "    \n",
    "for i in range(1):\n",
    "  \n",
    "  question = input(\"Himalay: \")\n",
    "  print(\"Himlay: \", question)\n",
    "  \n",
    "  \n",
    "  chain = create_extraction_chain(schema, llmdata)\n",
    "  converted_answer = chain.run(question)\n",
    "  if len(converted_answer) > 0:\n",
    "    check_phone_name(converted_answer[0])\n",
    "  print(f\"user converted answer - {converted_answer}\")\n",
    "  \n",
    "  ai_msg = rag_chain.invoke({\"question\": question, \"chat_history\": chat_history})\n",
    "  \n",
    "  \n",
    "  print(\"AI Response: \",ai_msg)\n",
    "  print(\"--------------------------------------------------------------\")\n",
    "  chat_history.extend([HumanMessage(content=question), ai_msg])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
